<table class="imgtable">
  <tr>
    <td>
      <img src="assets/photo.jpg" alt="Haichao Wang" width="150px" style="border-radius:5px; margin-right:20px;" onerror="this.src='https://ui-avatars.com/api/?name=Haichao+Wang&size=200'">
    </td>
    <td align="left">
      <p>Master Student<br />
      <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a><br />
      Email: <a href="mailto:wanghc23@mails.tsinghua.edu.cn">wanghc23@mails.tsinghua.edu.cn</a></p>
    </td>
  </tr>
</table>

## About Me

I am a third-year master student in [Tsinghua University](https://www.tsinghua.edu.cn), under the supervision of Prof. Yuxing Han. I earned my bachelor's degree from [Beijing Jiaotong University](https://www.bjtu.edu.cn) in 2023.

My research interest focuses on **Machine Learning** and **Computer Vision**, especially **Efficient AI** algorithms and systems. From 2021, I started my research on efficient physiological time series analysis based on knowledge distillation. Now, I focus on efficient video computer vision systems with video motion estimation.

Feel free to contact me by email if you are interest in discussion or collarboration with me.

## Education

- **Master of Science**
  - Data Science and Information Technology, [Tsinghua University](https://www.tsinghua.edu.cn)
  - 2023 - Present
  - Advisor: Prof. Yuxing Han
- **Bachelor of Engineering**
  - Computer Science and Technology, [Beijing Jiaotong University](https://www.bjtu.edu.cn)
  - 2019 - 2023

## Publications

1. Liang, Heng, Yucheng Liu, **Haichao Wang**, and Ziyu Jia. "Teacher Assistant-Based Knowledge Distillation Extracting Multi-Level Features on Single Channel Sleep EEG." In *International Joint Conference on Artificial Intelligence (IJCAI)*. 2023. [[Paper]](http://ijcai.org/proceedings/2023/0439.pdf)

2. Liu, Yucheng, Ziyu Jia, and **Haichao Wang**. "EmotionKD: A Cross-Modal Knowledge Distillation Framework for Emotion Recognition Based on Physiological Signals." In *ACM International Conference on Multimedia (ACM MM)*, 6122â€“31. 2023. [[Paper]](https://dl.acm.org/doi/abs/10.1145/3581783.3612277)

3. Jia, Ziyu, Heng Liang, Yucheng Liu, **Haichao Wang**, and Tianzi Jiang. "DistillSleepNet: Heterogeneous Multi-Level Knowledge Distillation via Teacher Assistant for Sleep Staging." *IEEE Transactions on Big Data*, 2024. [[Paper]](https://ieeexplore.ieee.org/abstract/document/10663937)

4. Jia, Ziyu, **Haichao Wang**, Yucheng Liu, and Tianzi Jiang. "Mutual Distillation Extracting Spatial-Temporal Knowledge for Lightweight Multi-Channel Sleep Stage Classification." In *ACM SIGKDD Conference on Knowledge Discovery and Data Mining*. 2024. [[Paper]](https://dl.acm.org/doi/abs/10.1145/3637528.3671981)

5. Jia, Ziyu, Heng Liang, **Haichao Wang**, Yucheng Liu, and Tianzi Jiang. "Cross-Modal Knowledge Distillation for Enhanced Unimodal Emotion Recognition." *IEEE Transactions on Affective Computing*, 2025. [[Paper]](https://ieeexplore.ieee.org/abstract/document/11052680)

6. **Haichao Wang**, Gene Wen, and Yuxing Han. "Leveraging Motion Estimation for Efficient Bayer-Domain Computer Vision." arXiv preprint arXiv:2501.15119 (2025). [[arXiv]](https://arxiv.org/abs/2501.15119)

7. **Haichao Wang**, Gene Wen, and Yuxing Han. "Efficient Bayer-Domain Video Computer Vision with Fast Motion Estimation and Learned Perception Residual." arXiv preprint arXiv:2508.05990 (2025). [[arXiv]](https://arxiv.org/abs/2508.05990)
